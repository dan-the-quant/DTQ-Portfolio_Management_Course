{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb95aa40-adff-4669-bf50-5ec2373212db",
   "metadata": {},
   "source": [
    "# Fama and French Factor Model #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a23296-71d4-4783-9519-5c8a844d3f38",
   "metadata": {},
   "source": [
    "### Import Data ###"
   ]
  },
  {
   "cell_type": "code",
   "id": "bbdbc010-16d6-44dd-8580-2cb3e8cc947a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:32:07.677647Z",
     "start_time": "2025-04-21T22:32:05.965479Z"
    }
   },
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Data Management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Handle Files\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Import Local Functions\n",
    "sys.path.append(os.path.abspath(\"../source\"))\n",
    "from functions import import_stock_universe\n",
    "from capm_toolkit import compute_daily_returns\n",
    "from capm_toolkit import compute_excess_returns\n",
    "from portfolios_toolkit import calculate_analytics"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f8ca48f6-056c-4503-b64e-80c7fc827e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:34:41.148971Z",
     "start_time": "2025-04-21T22:34:41.001656Z"
    }
   },
   "source": [
    "# Get the important data for the Risk Free Rate\n",
    "\n",
    "rfr = pd.read_csv(r\"..\\additional_data\\rfr.csv\")\n",
    "rfr = rfr.set_index('Date')\n",
    "rfr.index = pd.to_datetime(rfr.index, dayfirst=True)\n",
    "\n",
    "# Get the important data for the S&P500\n",
    "\n",
    "sp500 = pd.read_csv(r\"..\\additional_data\\sp500.csv\")\n",
    "sp500 = sp500.set_index('Date')\n",
    "sp500.index = pd.to_datetime(sp500.index)\n",
    "\n",
    "# Get the data for the Stocks' Betas\n",
    "\n",
    "betas_df = pd.read_csv(r\"..\\additional_data\\capm_hbetas.csv\")\n",
    "betas_df = betas_df.set_index('date')\n",
    "betas_df.index = pd.to_datetime(betas_df.index)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "194144db-cd57-48af-a995-23e053ff15fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:34:52.985440Z",
     "start_time": "2025-04-21T22:34:41.879245Z"
    }
   },
   "source": [
    "# Dictionary to store the DataFrames\n",
    "folder_path = r\"..\\stocks\"\n",
    "\n",
    "dataframes = import_stock_universe(\n",
    "    folder_path,\n",
    "    ['Adjusted_close', 'Company Market Cap', 'Price_to_Book_inverse'],\n",
    "    ['adj_close', 'mkt_cap', 'btp'],\n",
    ")"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9628cf0d-0761-44af-9ed8-cb706879bb6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:34:55.612719Z",
     "start_time": "2025-04-21T22:34:55.362210Z"
    }
   },
   "source": [
    "# Create a whole new dataframe that contains all the stocks betas\n",
    "rets_series = []\n",
    "\n",
    "for stock, df in dataframes.items():\n",
    "    series = df['adj_close'].pct_change(1).rename(stock)  \n",
    "    series = series.iloc[1:]\n",
    "    rets_series.append(series)\n",
    "\n",
    "# Concat\n",
    "returns_df = pd.concat(rets_series, axis=1)\n",
    "returns_df = returns_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "# Drop nans\n",
    "returns_df.dropna(inplace = True)\n",
    "\n",
    "returns_df"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "24f158a5-a29a-49db-be3e-11b11bbafcc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:34:58.550314Z",
     "start_time": "2025-04-21T22:34:58.472534Z"
    }
   },
   "source": [
    "# Create a whole new dataframe that contains all the stocks betas\n",
    "mktcap_series = []\n",
    "\n",
    "for stock, df in dataframes.items():\n",
    "    series = df['mkt_cap'].rename(stock)  \n",
    "    mktcap_series.append(series)\n",
    "\n",
    "# Concat\n",
    "mktcap_df = pd.concat(mktcap_series, axis=1)\n",
    "\n",
    "# Apply Logs and EMA (maybe)\n",
    "mktcap_df = np.log(mktcap_df)\n",
    "mktcap_df = mktcap_df.ewm(span=5, adjust = False).mean()\n",
    "mktcap_df = mktcap_df.bfill()\n",
    "mktcap_df"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d72e1f23-526e-45be-af18-b0177bb34c73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:35:45.612862Z",
     "start_time": "2025-04-21T22:35:45.528340Z"
    }
   },
   "source": [
    "# Create a whole new dataframe that contains all the stocks betas\n",
    "\n",
    "btp_series = []\n",
    "\n",
    "for stock, df in dataframes.items():\n",
    "    series = df['btp'].rename(stock)  \n",
    "    series = series.iloc[1:]\n",
    "    btp_series.append(series)\n",
    "\n",
    "# Concat\n",
    "btp_df = pd.concat(btp_series, axis=1)\n",
    "\n",
    "# EMA\n",
    "btp_df = btp_df.ewm(span=5, adjust = False).mean()\n",
    "btp_df = btp_df.bfill()\n",
    "\n",
    "btp_df"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b616c9a9-8452-489b-a3db-c68409b199f0",
   "metadata": {},
   "source": "## Create the Fama & French Portfolios ##"
  },
  {
   "cell_type": "code",
   "id": "cddee2e5-e58e-47f3-afcc-5f25438583d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:38:13.917789Z",
     "start_time": "2025-04-21T22:38:13.900826Z"
    }
   },
   "source": [
    "# Define the Decomposition Function\n",
    "def fama_and_french_decomposition(\n",
    "    target_df, \n",
    "    mktcap_df, \n",
    "    value_df\n",
    "):\n",
    "    # Common Indexes\n",
    "    common_index = target_df.index.intersection(value_df.index).intersection(mktcap_df.index)\n",
    "    \n",
    "    # Reindex\n",
    "    target_df = target_df.loc[common_index]\n",
    "    mktcap_df = mktcap_df.loc[common_index]\n",
    "    value_df = value_df.loc[common_index]\n",
    "\n",
    "    # Initialize lists to store portfolio returns\n",
    "    small_low_list, small_neutral_list, small_high_list = [], [], []\n",
    "    big_low_list, big_neutral_list, big_high_list = [], [], []\n",
    "    \n",
    "    # Get unique quarters\n",
    "    quarters = sorted(set([date.to_period('Q') for date in common_index]))\n",
    "    \n",
    "    # Dictionary to store quarterly classifications and weights\n",
    "    quarterly_classifications = {}\n",
    "\n",
    "    for quarter in quarters:\n",
    "        # Select only the last available date of the quarter\n",
    "        quarter_dates = [date for date in common_index if date.to_period('Q') == quarter]\n",
    "        rebalance_date = quarter_dates[-1]  # Last day of the quarter\n",
    "        \n",
    "        # Size factor for rebalance date\n",
    "        size_factor_df = pd.DataFrame([mktcap_df.loc[rebalance_date]], index=['mkt_cap']).T.dropna()\n",
    "        \n",
    "        # Value factor (P/B ratio) for rebalance date\n",
    "        value_factor_df = pd.DataFrame([value_df.loc[rebalance_date]], index=['btp']).T.dropna()\n",
    "\n",
    "        # Threshold for size\n",
    "        median = size_factor_df['mkt_cap'].median()\n",
    "\n",
    "        # Classify stocks into Low, Neutral, and High based on quantiles\n",
    "        lower = value_factor_df['btp'].quantile(0.3)\n",
    "        upper = value_factor_df['btp'].quantile(0.7)\n",
    "\n",
    "        # Merge the two\n",
    "        combined_df = size_factor_df.join(value_factor_df, how='inner')\n",
    "\n",
    "        # Classify for Size\n",
    "        combined_df['size_class'] = 'small'\n",
    "        combined_df.loc[combined_df['mkt_cap'] > median, 'size_class'] = 'big'\n",
    "\n",
    "        # Classify for Value\n",
    "        combined_df['value_class'] = 'neutral'\n",
    "        combined_df.loc[combined_df['btp'] <= lower, 'value_class'] = 'low'\n",
    "        combined_df.loc[combined_df['btp'] >= upper, 'value_class'] = 'high'\n",
    "        \n",
    "        # Create the FF Portfolios\n",
    "        combined_df['ff_class'] = combined_df['size_class'] + '_' + combined_df['value_class']\n",
    "        \n",
    "        # Market cap data\n",
    "        market_caps_df = pd.DataFrame([mktcap_df.loc[rebalance_date]], index=['mkt_cap']).T\n",
    "        \n",
    "        # Assign market caps to value classes\n",
    "        small_low_mktcap_df = market_caps_df.loc[combined_df[combined_df['ff_class'] == 'small_low'].index]\n",
    "        small_neutral_mktcap_df = market_caps_df.loc[combined_df[combined_df['ff_class'] == 'small_neutral'].index]\n",
    "        small_high_mktcap_df = market_caps_df.loc[combined_df[combined_df['ff_class'] == 'small_high'].index]\n",
    "        big_low_mktcap_df = market_caps_df.loc[combined_df[combined_df['ff_class'] == 'big_low'].index]\n",
    "        big_neutral_mktcap_df = market_caps_df.loc[combined_df[combined_df['ff_class'] == 'big_neutral'].index]\n",
    "        big_high_mktcap_df = market_caps_df.loc[combined_df[combined_df['ff_class'] == 'big_high'].index]\n",
    "        \n",
    "        # Compute weights\n",
    "        small_low_weights = small_low_mktcap_df['mkt_cap'] / small_low_mktcap_df['mkt_cap'].sum()\n",
    "        small_neutral_weights = small_neutral_mktcap_df['mkt_cap'] / small_neutral_mktcap_df['mkt_cap'].sum()\n",
    "        small_high_weights = small_high_mktcap_df['mkt_cap'] / small_high_mktcap_df['mkt_cap'].sum()\n",
    "        big_low_weights = big_low_mktcap_df['mkt_cap'] / big_low_mktcap_df['mkt_cap'].sum()\n",
    "        big_neutral_weights = big_neutral_mktcap_df['mkt_cap'] / big_neutral_mktcap_df['mkt_cap'].sum()\n",
    "        big_high_weights = big_high_mktcap_df['mkt_cap'] / big_high_mktcap_df['mkt_cap'].sum()\n",
    "        \n",
    "        # Store classifications and weights\n",
    "        quarterly_classifications[quarter] = {\n",
    "            \"small_low\": small_low_weights,\n",
    "            \"small_neutral\": small_neutral_weights,\n",
    "            \"small_high\": small_high_weights,\n",
    "            \"big_low\": big_low_weights, \n",
    "            \"big_neutral\": big_neutral_weights,\n",
    "            \"big_high\": big_high_weights,\n",
    "        }\n",
    "    \n",
    "    # Iterate over all available dates to compute daily returns\n",
    "    for date in common_index:\n",
    "        quarter_key = date.to_period('Q')  # Get quarter of the current date\n",
    "        \n",
    "        if quarter_key in quarterly_classifications:\n",
    "            # Retrieve stored classification and weights\n",
    "            small_low_weights = quarterly_classifications[quarter_key][\"small_low\"]\n",
    "            small_neutral_weights = quarterly_classifications[quarter_key][\"small_neutral\"]\n",
    "            small_high_weights = quarterly_classifications[quarter_key][\"small_high\"]\n",
    "            big_low_weights = quarterly_classifications[quarter_key][\"big_low\"]\n",
    "            big_neutral_weights = quarterly_classifications[quarter_key][\"big_neutral\"]\n",
    "            big_high_weights = quarterly_classifications[quarter_key][\"big_high\"]\n",
    "            \n",
    "            # Retrieve daily returns\n",
    "            target = pd.DataFrame([target_df.loc[date]], index=['returns']).T\n",
    "            \n",
    "            small_low_returns = target.reindex(small_low_weights.index).dropna()\n",
    "            small_neutral_returns = target.reindex(small_neutral_weights.index).dropna()\n",
    "            small_high_returns = target.reindex(small_high_weights.index).dropna()\n",
    "            big_low_returns = target.reindex(big_low_weights.index).dropna()\n",
    "            big_neutral_returns = target.reindex(big_neutral_weights.index).dropna()\n",
    "            big_high_returns = target.reindex(big_high_weights.index).dropna()\n",
    "            \n",
    "            # Compute portfolio returns\n",
    "            small_low_result = small_low_weights.reindex(small_low_returns.index).T @ small_low_returns\n",
    "            small_neutral_result = small_neutral_weights.reindex(small_neutral_returns.index).T @ small_neutral_returns\n",
    "            small_high_result = small_high_weights.reindex(small_high_returns.index).T @ small_high_returns\n",
    "            big_low_result = big_low_weights.reindex(big_low_returns.index).T @ big_low_returns\n",
    "            big_neutral_result = big_neutral_weights.reindex(big_neutral_returns.index).T @ big_neutral_returns\n",
    "            big_high_result = big_high_weights.reindex(big_high_returns.index).T @ big_high_returns\n",
    "            \n",
    "            # Store results\n",
    "            small_low_list.append(small_low_result.values[0] if not small_low_result.empty else None)\n",
    "            small_neutral_list.append(small_neutral_result.values[0] if not small_neutral_result.empty else None)\n",
    "            small_high_list.append(small_high_result.values[0] if not small_high_result.empty else None)\n",
    "            big_low_list.append(big_low_result.values[0] if not big_low_result.empty else None)\n",
    "            big_neutral_list.append(big_neutral_result.values[0] if not big_neutral_result.empty else None)\n",
    "            big_high_list.append(big_high_result.values[0] if not big_high_result.empty else None)\n",
    "\n",
    "    # Create final DataFrame\n",
    "    ff_portfolios = pd.DataFrame({\n",
    "        'small_high': small_high_list,\n",
    "        'small_neutral': small_neutral_list,\n",
    "        'small_low': small_low_list,\n",
    "        'big_high': big_high_list,\n",
    "        'big_neutral': big_neutral_list,\n",
    "        'big_low': big_low_list\n",
    "    }, index=common_index)\n",
    "    \n",
    "    return ff_portfolios"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fb87c10c-9087-4311-96fd-7fd0da4a0855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:38:25.552856Z",
     "start_time": "2025-04-21T22:38:16.268757Z"
    }
   },
   "source": [
    "# Create DataFrames\n",
    "\n",
    "ff_portfolio_returns = fama_and_french_decomposition(returns_df, mktcap_df, btp_df)\n",
    "\n",
    "ff_portfolio_returns"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e73538eb-a548-4fc7-a51b-0155a42f271a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:38:40.462765Z",
     "start_time": "2025-04-21T22:38:40.443026Z"
    }
   },
   "source": [
    "# Check the Annualized Mean Returns\n",
    "\n",
    "ff_portfolio_analytics = calculate_analytics(ff_portfolio_returns)\n",
    "\n",
    "ff_portfolio_analytics"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "75947df4-2bd2-4098-aae3-ad5f36ccc5a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:39:09.943129Z",
     "start_time": "2025-04-21T22:39:09.736434Z"
    }
   },
   "source": [
    "# Create Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ff_portfolio_returns.cumsum(), label=ff_portfolio_returns.columns, alpha=1)\n",
    "\n",
    "# Config\n",
    "plt.title('Cumulative Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "eeab3f16-379a-44f9-aed0-1568f75e39cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:39:43.129370Z",
     "start_time": "2025-04-21T22:39:35.148888Z"
    }
   },
   "source": [
    "# Create DataFrames\n",
    "\n",
    "ff_portfolio_betas = fama_and_french_decomposition(betas_df, mktcap_df, btp_df)\n",
    "\n",
    "ff_portfolio_betas"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b39a74d5-2777-41d2-ade0-75b643a57b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:39:43.303485Z",
     "start_time": "2025-04-21T22:39:43.129370Z"
    }
   },
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ff_portfolio_betas.ewm(span=21, adjust = False).mean(), label=ff_portfolio_betas.columns, alpha=1)\n",
    "plt.axhline(y=1, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('Betas (Size Adjusted) Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Betas')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a8e8eaa1-138e-4494-b26a-080b675e62a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:40:25.956202Z",
     "start_time": "2025-04-21T22:40:25.943438Z"
    }
   },
   "source": [
    "# Calculate the SMB Premium\n",
    "\n",
    "SMB = (1/3)*(ff_portfolio_returns['small_low'] + ff_portfolio_returns['small_neutral'] + ff_portfolio_returns['small_high']) \\\n",
    "    - (1/3)*(ff_portfolio_returns['big_low'] + ff_portfolio_returns['big_neutral'] + ff_portfolio_returns['big_high'])\n",
    "\n",
    "SMB.name = 'SMB'\n",
    "SMB"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "33610c0c-f549-4e32-b993-8f94a7886c69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:40:30.460522Z",
     "start_time": "2025-04-21T22:40:30.326205Z"
    }
   },
   "source": [
    "# Plot SMB\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(SMB.cumsum(), label='SMB Premium', color = 'salmon', alpha=1)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('SMB Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "99f31680-7541-4298-859c-04b45f68f380",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:40:48.825578Z",
     "start_time": "2025-04-21T22:40:48.815832Z"
    }
   },
   "source": [
    "# Calculate the HML Premium\n",
    "\n",
    "HML = (1/2)*(ff_portfolio_returns['small_high'] + ff_portfolio_returns['big_high']) \\\n",
    "    - (1/2)*(ff_portfolio_returns['small_low'] + ff_portfolio_returns['big_low'])\n",
    "\n",
    "HML.name = 'HML'\n",
    "\n",
    "HML "
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "488df3a7-8416-4f9d-90f2-a94ef0c635fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:40:53.839667Z",
     "start_time": "2025-04-21T22:40:53.697291Z"
    }
   },
   "source": [
    "# Plot HML\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(HML.cumsum(), label='HML Premium', color = 'salmon', alpha=1)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('HML Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b0d6b78e-0452-4797-95a6-72376a6942bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:41:26.999803Z",
     "start_time": "2025-04-21T22:41:26.993314Z"
    }
   },
   "source": [
    "# Create the market data\n",
    "daily_rfr = compute_daily_returns(rfr['risk_free_rate'])\n",
    "market_excess_returns = compute_excess_returns(sp500['sp_500'], rfr['risk_free_rate'])"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "363ab27e-b847-4204-bda8-176dd74c5ab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:41:31.827856Z",
     "start_time": "2025-04-21T22:41:31.811153Z"
    }
   },
   "source": [
    "# Check the Correlation\n",
    "\n",
    "print(f'SMB premium correlation  with HML premium: {SMB.corr(HML)}')\n",
    "print(f'SMB premium correlation  with market premium: {SMB.corr(market_excess_returns)}')\n",
    "print(f'HML premium correlation  with market premium: {HML.corr(market_excess_returns)}')"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1e1925ed-42ae-4079-8c91-f530122e2aae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:41:37.567754Z",
     "start_time": "2025-04-21T22:41:37.429589Z"
    }
   },
   "source": [
    "# Plot HML\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(market_excess_returns.cumsum(), label='Market Premium', alpha=1)\n",
    "plt.plot(SMB.cumsum(), label='SMB Premium', alpha=1)\n",
    "plt.plot(HML.cumsum(), label='HML Premium', alpha=1)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('HML Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "35a10c95-0752-4eee-9634-99e175b753a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:42:04.857703Z",
     "start_time": "2025-04-21T22:42:04.832874Z"
    }
   },
   "source": [
    "# Store both series\n",
    "\n",
    "SMB.to_csv(r\"..\\additional_data\\famafrench_smb.csv\")\n",
    "HML.to_csv(r\"..\\additional_data\\famafrench_hml.csv\")"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a91ad-18d7-4265-b84f-935799324f5c",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
