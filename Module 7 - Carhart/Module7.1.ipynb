{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199116d8-14cd-46ae-b0fe-a5f7456b786f",
   "metadata": {},
   "source": [
    "# The Cahart Four Factor Model #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292a964-2ba8-40e7-bfd6-8afa63759f5d",
   "metadata": {},
   "source": [
    "### Using Relative Strenght to approach Momentum ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9079c91e-252e-4ceb-9f17-658b6308c8ee",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Data Management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistics\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Manipulate Files\n",
    "import os\n",
    "\n",
    "# Pretty Notation\n",
    "from IPython.display import display, Math"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4ffc4758-71f3-46cc-98ed-f1004f67c880",
   "metadata": {},
   "source": [
    "# Get the important data for the Risk Free Rate\n",
    "\n",
    "rfr = pd.read_csv(r\"..\\additional_data\\rfr.csv\")\n",
    "rfr = rfr.set_index('Date')\n",
    "rfr.index = pd.to_datetime(rfr.index, dayfirst=True)\n",
    "\n",
    "# Get the important data for the S&P500\n",
    "\n",
    "sp500 = pd.read_csv(r\"..\\additional_data\\sp500.csv\")\n",
    "sp500 = sp500.set_index('Date')\n",
    "sp500.index = pd.to_datetime(sp500.index)\n",
    "\n",
    "# Get the data for the Stocks' Betas\n",
    "\n",
    "betas_df = pd.read_csv(r\"..\\additional_data\\betas.csv\")\n",
    "betas_df = betas_df.set_index('Date')\n",
    "betas_df.index = pd.to_datetime(betas_df.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "567dc7b0-12a4-4466-a6cd-df8f0b0bb65f",
   "metadata": {},
   "source": [
    "# Folder Path\n",
    "folder_path = r\"..\\stocks\"\n",
    "\n",
    "# Dictionary to store the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# List all files in the folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        # Full path to the file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.set_index(\"Date\")\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        df = df[['Adjusted_close', 'Market_cap_calculado']]\n",
    "\n",
    "        df = df.rename(columns={\n",
    "            'Adjusted_close':'adj_close',\n",
    "            'Market_cap_calculado':'market_cap',\n",
    "        })\n",
    "\n",
    "        # Fill nans\n",
    "        df['adj_close'] = df['adj_close'].interpolate(method='linear')\n",
    "        df['market_cap'] = df['market_cap'].interpolate(method='linear')\n",
    "\n",
    "        df = df.loc['2015-01-01':]\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        if len(df) >= 2000:\n",
    "            # File name without extension\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Guardar en el diccionario\n",
    "            dataframes[file_name] = df\n",
    "            print(f\"File loaded: {file_name} ({len(df)} rows)\")\n",
    "        else:\n",
    "            print(f\"File skipped (less than 2000 rows after cleaning): {file}\")\n",
    "\n",
    "print(f\"\\nTotal files loaded: {len(dataframes)}\")\n",
    "print(\"Files loaded:\", list(dataframes.keys()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b62d833d-80cd-447b-b0f8-f08a4337e234",
   "metadata": {},
   "source": [
    "# Create a whole new dataframe that contains all the stocks betas\n",
    "\n",
    "rets_series = []\n",
    "\n",
    "for stock, df in dataframes.items():\n",
    "    series = df['adj_close'].pct_change(1).rename(stock)  \n",
    "    series = series.iloc[1:]\n",
    "    rets_series.append(series)\n",
    "\n",
    "# Concat\n",
    "returns_df = pd.concat(rets_series, axis=1)\n",
    "returns_df = returns_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "returns_df.dropna(inplace = True)\n",
    "\n",
    "returns_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eff2372f-3c6c-4976-80eb-650db35ec678",
   "metadata": {},
   "source": [
    "# Create a whole new dataframe that contains all the stocks betas\n",
    "\n",
    "mktcap_series = []\n",
    "\n",
    "for stock, df in dataframes.items():\n",
    "    series = df['market_cap'].rename(stock)  \n",
    "    series = series.iloc[1:]\n",
    "    mktcap_series.append(series)\n",
    "\n",
    "# Concat\n",
    "mktcap_df = pd.concat(mktcap_series, axis=1)\n",
    "mktcap_df = mktcap_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "# Drop nans\n",
    "mktcap_df.dropna(inplace = True)\n",
    "\n",
    "# Apply Logs and EMA (maybe)\n",
    "mktcap_df = np.log(mktcap_df)\n",
    "mktcap_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b5d7960d-cdfe-4ae1-b731-866e4523d513",
   "metadata": {},
   "source": [
    "# Create the Weights function\n",
    "def wexp(N, half_life):\n",
    "    c = np.log(0.5)/half_life\n",
    "    n = np.array(range(N))\n",
    "    w = np.exp(c*n)\n",
    "    return np.flip(w/np.sum(w))\n",
    "\n",
    "def n_days_nonmiss(returns, tiny_ret=1e-6):\n",
    "    ix_ret_tiny = np.abs(returns) <= tiny_ret\n",
    "    return np.sum(~ix_ret_tiny, axis=0)\n",
    "\n",
    "def calc_rstr(returns, half_life=126, min_obs=100, tiny_ret=1e-6):\n",
    "    rstr = np.log(1.+returns)\n",
    "    if half_life == 0:\n",
    "        weights = np.ones_like(rstr)\n",
    "    else:\n",
    "        weights = len(returns) * np.asmatrix(wexp(len(returns),half_life)).T\n",
    "    rstr = np.sum(rstr * weights)\n",
    "    idx = n_days_nonmiss(returns) < min_obs\n",
    "    rstr.where(~idx, other=np.nan, inplace=True)\n",
    "    df = pd.Series(rstr)\n",
    "    df.name = returns.index[-1]\n",
    "    return df\n",
    "\n",
    "def rolling_calc_rstr(\n",
    "        returns,\n",
    "        window_size=252,\n",
    "        half_life=126,\n",
    "        min_obs=100\n",
    "):\n",
    "    rolling_results = []\n",
    "    range_to_iter = range(len(returns) - window_size + 1)\n",
    "    for i in range_to_iter:\n",
    "        window_returns = returns.iloc[i:i + window_size]\n",
    "        rs_i = calc_rstr(\n",
    "            returns=window_returns,\n",
    "            half_life=half_life,\n",
    "            min_obs=min_obs\n",
    "        )\n",
    "\n",
    "        rolling_results.append(rs_i)\n",
    "\n",
    "    return pd.concat(rolling_results, axis=1)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f4997b53-b1d8-469d-8be5-ebb1c00f9248",
   "metadata": {},
   "source": [
    "# Create a whole new dataframe that contains all the stocks betas\n",
    "relative_strenght_long = rolling_calc_rstr(\n",
    "    returns_df,\n",
    "    window_size=252,\n",
    "    half_life=126\n",
    ").T\n",
    "\n",
    "relative_strenght_short = rolling_calc_rstr(\n",
    "    returns_df,\n",
    "    window_size=28,\n",
    "    half_life=14,\n",
    "    min_obs=13\n",
    ").T"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a82f7fd5-18e2-42f2-a5ee-176bdf451625",
   "metadata": {},
   "source": [
    "relative_strenght = (relative_strenght_long - relative_strenght_short).dropna()\n",
    "\n",
    "relative_strenght"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ca9527ef-d1be-4d59-8074-9145a7345370",
   "metadata": {},
   "source": [
    "# Create Plot\n",
    "\n",
    "ticker = 'NVDA'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(relative_strenght[ticker], label=f'{ticker} Relative Strenght', alpha=1)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('Relative Strenght Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Relative Strenght')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "50c58321-d36a-4139-ab74-e971387461cc",
   "metadata": {},
   "source": [
    "# Store the Data\n",
    "\n",
    "relative_strenght.to_csv(r\"..\\additional_data\\momentum.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a793c2db-7a16-470a-9428-f403e9c1b21d",
   "metadata": {},
   "source": [
    "# Checar que dice Cahart al respecto >:\n",
    "# Sharpe Ratio decay\n",
    "# Fuerza de la señal dura un mes, entonces podemos hacer rebalanceo mensual para clasificar winners y losers pipipi\n",
    "# Podríamos ver otros factores"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "80688ffa-ceb0-420c-9cb9-6546fc92be5d",
   "metadata": {},
   "source": [
    "### Calculate the Momentum Portfolios ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "892ce189-3b63-423c-b0bd-48185fa89110",
   "metadata": {},
   "source": [
    "# Define the Decomposition Function\n",
    "def momentum_decomposition(\n",
    "    target_df, \n",
    "    mktcap_df, \n",
    "    momentum_df\n",
    "):\n",
    "    # Common Indexes\n",
    "    common_index = target_df.index.intersection(momentum_df.index).intersection(mktcap_df.index)\n",
    "    \n",
    "    # Reindex\n",
    "    target_df = target_df.loc[common_index]\n",
    "    mktcap_df = mktcap_df.loc[common_index]\n",
    "    momentum_df = momentum_df.loc[common_index]\n",
    "\n",
    "    # Initialize lists to store portfolio returns\n",
    "    winner_list, neutral_list, loser_list = [], [], []\n",
    "    \n",
    "    # Get unique quarters\n",
    "    months = sorted(set([date.to_period('M') for date in common_index]))\n",
    "    \n",
    "    # Dictionary to store quarterly classifications and weights\n",
    "    monthly_classifications = {}\n",
    "\n",
    "    for month in months:\n",
    "        # Select only the last available date of the quarter\n",
    "        month_dates = [date for date in common_index if date.to_period('M') == month]\n",
    "        rebalance_date = month_dates[-1]  # Last day of the quarter\n",
    "        \n",
    "        # Momentum Factor for rebalance date\n",
    "        momentum_factor_df = pd.DataFrame([momentum_df.loc[rebalance_date]], index=['mom']).T.dropna()\n",
    "        \n",
    "        # Classify stocks into Low, Neutral, and High based on quantiles\n",
    "        lower = momentum_factor_df['mom'].quantile(0.3)\n",
    "        upper = momentum_factor_df['mom'].quantile(0.7)\n",
    "\n",
    "        momentum_factor_df['momentum_class'] = 'neutral'\n",
    "        momentum_factor_df.loc[momentum_factor_df['mom'] <= lower, 'momentum_class'] = 'loser'\n",
    "        momentum_factor_df.loc[momentum_factor_df['mom'] >= upper, 'momentum_class'] = 'winner'\n",
    "        \n",
    "        # Market cap data\n",
    "        market_caps_df = pd.DataFrame([mktcap_df.loc[rebalance_date]], index=['mkt_cap']).T\n",
    "        \n",
    "        # Assign market caps to value classes\n",
    "        loser_mktcap_df = market_caps_df.loc[momentum_factor_df[momentum_factor_df['momentum_class'] == 'loser'].index]\n",
    "        neutral_mktcap_df = market_caps_df.loc[momentum_factor_df[momentum_factor_df['momentum_class'] == 'neutral'].index]\n",
    "        winner_mktcap_df = market_caps_df.loc[momentum_factor_df[momentum_factor_df['momentum_class'] == 'winner'].index]\n",
    "        \n",
    "        # Compute weights\n",
    "        loser_weights = loser_mktcap_df['mkt_cap'] / loser_mktcap_df['mkt_cap'].sum()\n",
    "        neutral_weights = neutral_mktcap_df['mkt_cap'] / neutral_mktcap_df['mkt_cap'].sum()\n",
    "        winner_weights = winner_mktcap_df['mkt_cap'] / winner_mktcap_df['mkt_cap'].sum()\n",
    "        \n",
    "        # Store classifications and weights\n",
    "        monthly_classifications[month] = {\n",
    "            \"loser\": loser_weights,\n",
    "            \"neutral\": neutral_weights,\n",
    "            \"winner\": winner_weights\n",
    "        }\n",
    "    \n",
    "    # Iterate over all available dates to compute daily returns\n",
    "    for date in common_index:\n",
    "        month_key = date.to_period('M')  # Get quarter of the current date\n",
    "        \n",
    "        if month_key in monthly_classifications:\n",
    "            # Retrieve stored classification and weights\n",
    "            loser_weights = monthly_classifications[month_key][\"loser\"]\n",
    "            neutral_weights = monthly_classifications[month_key][\"neutral\"]\n",
    "            winner_weights = monthly_classifications[month_key][\"winner\"]\n",
    "            \n",
    "            # Retrieve daily returns\n",
    "            target = pd.DataFrame([target_df.loc[date]], index=['returns']).T\n",
    "            \n",
    "            loser_returns = target.reindex(loser_weights.index).dropna()\n",
    "            neutral_returns = target.reindex(neutral_weights.index).dropna()\n",
    "            winner_returns = target.reindex(winner_weights.index).dropna()\n",
    "            \n",
    "            # Compute portfolio returns\n",
    "            loser_result = loser_weights.reindex(loser_returns.index).T @ loser_returns\n",
    "            neutral_result = neutral_weights.reindex(neutral_returns.index).T @ neutral_returns\n",
    "            winner_result = winner_weights.reindex(winner_returns.index).T @ winner_returns\n",
    "            \n",
    "            # Store results\n",
    "            loser_list.append(loser_result.values[0] if not loser_result.empty else None)\n",
    "            neutral_list.append(neutral_result.values[0] if not neutral_result.empty else None)\n",
    "            winner_list.append(winner_result.values[0] if not winner_result.empty else None)\n",
    "\n",
    "    # Create final DataFrame\n",
    "    momentum_portfolios = pd.DataFrame({\n",
    "        'winner': winner_list,\n",
    "        'neutral': neutral_list,\n",
    "        'loser': loser_list\n",
    "    }, index=common_index)\n",
    "    \n",
    "    return momentum_portfolios"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "af49a3f0-47fe-47cd-8b4f-ecc1b0bfbfb8",
   "metadata": {},
   "source": [
    "# Create DataFrames\n",
    "\n",
    "momentum_portfolios_returns = momentum_decomposition(returns_df, mktcap_df, relative_strenght)\n",
    "\n",
    "momentum_portfolios_returns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cc6e58de-9b58-400d-b028-91070e72e241",
   "metadata": {},
   "source": [
    "# Create Plot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(momentum_portfolios_returns.cumsum(), label=momentum_portfolios_returns.columns, alpha=1)\n",
    "\n",
    "# Config\n",
    "plt.title('Cumulative Returns (Momentum Adjusted) Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4ac4c597-b4a8-4131-9f94-572dca4e7445",
   "metadata": {},
   "source": [
    "# Create DataFrames\n",
    "\n",
    "momentum_portfolios_betas = momentum_decomposition(betas_df, mktcap_df, relative_strenght)\n",
    "\n",
    "momentum_portfolios_betas"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "577ee268-bb57-493a-a434-ba75bb47874b",
   "metadata": {},
   "source": [
    "# Create Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(momentum_portfolios_betas.ewm(span=21, adjust = False).mean(), label=momentum_portfolios_betas.columns, alpha=1)\n",
    "plt.axhline(y=1, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('Betas (Size Adjusted) Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Betas')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a79a3e44-071f-4467-906b-7d69a5db7d7e",
   "metadata": {},
   "source": [
    "# Create the data\n",
    "daily_rfr = (((1 + (rfr['risk_free_rate'].div(100)))**(1/360)) - 1)\n",
    "benchmark_returns = sp500['sp_500'].pct_change(1)\n",
    "\n",
    "# Create the Excess Returns\n",
    "market_excess_returns = benchmark_returns - daily_rfr"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "03c45eda-6994-4b33-a4ac-625b5c1c9699",
   "metadata": {},
   "source": [
    "# Create the regression dataframe\n",
    "momentum_regression_df = pd.DataFrame(index = momentum_portfolios_returns.index)\n",
    "\n",
    "momentum_regression_df['winners_excess_returns'] = momentum_portfolios_returns['winner'] - daily_rfr\n",
    "momentum_regression_df['losers_excess_returns'] = momentum_portfolios_returns['loser'] - daily_rfr\n",
    "momentum_regression_df['market_excess_returns'] = market_excess_returns\n",
    "momentum_regression_df.dropna(inplace = True)\n",
    "\n",
    "momentum_regression_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ad7c7be3-3b0b-43ca-bb9a-4a1b23cae8b1",
   "metadata": {},
   "source": [
    "# Calculate the Beta for the Winner Portfolio\n",
    "\n",
    "y = momentum_regression_df['winners_excess_returns']\n",
    "\n",
    "x = momentum_regression_df['market_excess_returns']\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Calculate Weights\n",
    "window = len(y)\n",
    "weights = window * wexp(window, window/2)\n",
    "\n",
    "#Model specification\n",
    "model = sm.WLS(\n",
    "    y, \n",
    "    x,\n",
    "    missing='drop',\n",
    "    weights=weights,\n",
    "    )   \n",
    "     \n",
    "#the results of the model\n",
    "results = model.fit() \n",
    "    \n",
    "#here we check the summary\n",
    "print(results.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "621079ea-f466-4e92-ba84-470c4257f918",
   "metadata": {},
   "source": [
    "# Calculate the Beta for the Loser Portfolio\n",
    "\n",
    "y = momentum_regression_df['losers_excess_returns']\n",
    "\n",
    "x = momentum_regression_df['market_excess_returns']\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Calculate Weights\n",
    "window = len(y)\n",
    "weights = window * wexp(window, window/2)\n",
    "\n",
    "#Model specification\n",
    "model = sm.WLS(\n",
    "    y, \n",
    "    x,\n",
    "    missing='drop',\n",
    "    weights=weights,\n",
    "    )   \n",
    "     \n",
    "#the results of the model\n",
    "results = model.fit() \n",
    "    \n",
    "#here we check the summary\n",
    "print(results.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "277a473c-e5fb-4e9e-890c-e3f3ba6f7d26",
   "metadata": {},
   "source": [
    "# Calculate the WML Premium\n",
    "\n",
    "momentum_regression_df['WML'] = momentum_portfolios_returns['winner'] - momentum_portfolios_returns['loser']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "29d18059-601a-4033-a94f-cd0d5d99e217",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(momentum_regression_df['WML'].cumsum(), label='WML Premium', color = 'salmon', alpha=1)\n",
    "\n",
    "# Config\n",
    "plt.title('WML Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "266cdcdd-95f9-4a44-89f0-ed2a8eb3a9f2",
   "metadata": {},
   "source": [
    "# Check the Correlation with the Market\n",
    "\n",
    "momentum_regression_df['WML'].corr(momentum_regression_df['market_excess_returns'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c310a26c-6738-4e73-a297-0b1532ab8f3e",
   "metadata": {},
   "source": [
    "# Calculate the Beta for the WML premium\n",
    "\n",
    "y = momentum_regression_df['WML']\n",
    "\n",
    "x = momentum_regression_df['market_excess_returns']\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Calculate Weights\n",
    "window = len(y)\n",
    "weights = window * wexp(window, window/2)\n",
    "\n",
    "#Model specification\n",
    "model = sm.WLS(\n",
    "    y, \n",
    "    x,\n",
    "    missing='drop',\n",
    "    weights=weights,\n",
    "    )   \n",
    "     \n",
    "#the results of the model\n",
    "results = model.fit() \n",
    "    \n",
    "#here we check the summary\n",
    "print(results.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ed6b834d-2d33-4dc5-b77d-bf413e911e2f",
   "metadata": {},
   "source": [
    "# Store the Premium\n",
    "\n",
    "momentum_regression_df['WML'].to_csv(r\"..\\additional_data\\WML.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43a8c6-76f3-489d-91ab-d84fae488fe7",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
