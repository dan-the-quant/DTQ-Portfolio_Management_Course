{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c68538b-78c3-4122-bdb4-76ee5c29f6c4",
   "metadata": {},
   "source": [
    "# Fama-MacBeth Regression #\n",
    "\n",
    "### Market, Size, Value, Momentum and Beta ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adaeccdb-13e7-4a58-ab99-0206cc322c7d",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Data Management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Manipulate Files\n",
    "import os\n",
    "\n",
    "# Pretty Notation\n",
    "from IPython.display import display, Math"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52b0635c-f03a-4568-9506-ab5a442f1ebe",
   "metadata": {},
   "source": [
    "# Get the important data for the Risk Free Rate\n",
    "\n",
    "rfr = pd.read_csv(r\"..\\additional_data\\rfr.csv\")\n",
    "rfr = rfr.set_index('Date')\n",
    "rfr.index = pd.to_datetime(rfr.index, dayfirst=True)\n",
    "\n",
    "# Get the important data for the S&P500\n",
    "\n",
    "sp500 = pd.read_csv(r\"..\\additional_data\\sp500.csv\")\n",
    "sp500 = sp500.set_index('Date')\n",
    "sp500.index = pd.to_datetime(sp500.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41eb431c-6bab-496d-9ae9-a205bd4f06b5",
   "metadata": {},
   "source": [
    "# Get the important data for the Betas\n",
    "\n",
    "# Market Betas\n",
    "carhart_mkt_betas = pd.read_csv(r\"..\\additional_data\\carhart_mkt_betas.csv\")\n",
    "carhart_mkt_betas.set_index('Date', inplace = True)\n",
    "carhart_mkt_betas.index = pd.to_datetime(carhart_mkt_betas.index)\n",
    "\n",
    "# SMB Betas\n",
    "carhart_smb_betas = pd.read_csv(r\"..\\additional_data\\carhart_smb_betas.csv\")\n",
    "carhart_smb_betas.set_index('Date', inplace = True)\n",
    "carhart_smb_betas.index = pd.to_datetime(carhart_smb_betas.index)\n",
    "\n",
    "# HML Betas\n",
    "carhart_hml_betas = pd.read_csv(r\"..\\additional_data\\carhart_hml_betas.csv\")\n",
    "carhart_hml_betas.set_index('Date', inplace = True)\n",
    "carhart_hml_betas.index = pd.to_datetime(carhart_hml_betas.index)\n",
    "\n",
    "# WML Betas\n",
    "carhart_wml_betas = pd.read_csv(r\"..\\additional_data\\carhart_wml_betas.csv\")\n",
    "carhart_wml_betas.set_index('Date', inplace = True)\n",
    "carhart_wml_betas.index = pd.to_datetime(carhart_wml_betas.index)\n",
    "\n",
    "# AMD Betas\n",
    "carhart_amd_betas = pd.read_csv(r\"..\\additional_data\\carhart_amd_betas.csv\")\n",
    "carhart_amd_betas.set_index('Date', inplace = True)\n",
    "carhart_amd_betas.index = pd.to_datetime(carhart_amd_betas.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6e7afc4-f460-4730-81da-bdc74c5ffcd4",
   "metadata": {},
   "source": [
    "# Dictionary to store the DataFrames\n",
    "folder_path = r\"..\\stocks\"\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "# List all files in the folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        # Full path to the file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.set_index(\"Date\")\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        df = df[['Adjusted_close', 'Company Market Cap']]\n",
    "\n",
    "        df = df.rename(columns={\n",
    "            'Adjusted_close':'adj_close',\n",
    "            'Company Market Cap':'market_cap',\n",
    "        })\n",
    "\n",
    "        # Fill nans\n",
    "        df['adj_close'] = df['adj_close'].interpolate(method='time')\n",
    "        df['market_cap'] = df['market_cap'].interpolate(method='time')\n",
    "\n",
    "        df = df.loc['2015-01-01':]\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        if len(df) >= 2000:\n",
    "            # File name without extension\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Guardar en el diccionario\n",
    "            dataframes[file_name] = df\n",
    "            print(f\"File loaded: {file_name} ({len(df)} rows)\")\n",
    "        else:\n",
    "            print(f\"File skipped (less than 2000 rows after cleaning): {file}\")\n",
    "\n",
    "print(f\"\\nTotal files loaded: {len(dataframes)}\")\n",
    "print(\"Files loaded:\", list(dataframes.keys()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58788207-f9c5-4d73-abc3-9e73e1d3b216",
   "metadata": {},
   "source": [
    "# Create a DataFrame\n",
    "mkt_cap_dict = {}\n",
    "\n",
    "# Recorrer cada ticker y DataFrame\n",
    "for ticker, df in dataframes.items():\n",
    "    \n",
    "    mkt_cap_dict[ticker] = df['market_cap']\n",
    "\n",
    "mkt_cap_df = pd.DataFrame.from_dict(mkt_cap_dict)\n",
    "\n",
    "mkt_cap_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fbf597e-5295-4ec2-90ab-2d4bdde445c7",
   "metadata": {},
   "source": [
    "# Let us obtain the betas of each stock\n",
    "\n",
    "returns_dic = {}\n",
    "\n",
    "for ticker, df in dataframes.items():\n",
    "    \n",
    "    returns_dic[ticker] = df['adj_close'].pct_change(1)\n",
    "\n",
    "returns_df = pd.DataFrame.from_dict(returns_dic)\n",
    "returns_df = returns_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "returns_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52fc4540-315b-4df4-8bd6-6dcd493ebfeb",
   "metadata": {},
   "source": [
    "# Intersec Dates\n",
    "common_dates = returns_df.index.intersection(carhart_mkt_betas.index)\n",
    "\n",
    "# Filter for common dates\n",
    "mkt_cap_df = mkt_cap_df.loc[common_dates]\n",
    "returns_df = returns_df.loc[common_dates]\n",
    "carhart_mkt_betas = carhart_mkt_betas.loc[common_dates]\n",
    "carhart_smb_betas = carhart_smb_betas.loc[common_dates]\n",
    "carhart_hml_betas = carhart_hml_betas.loc[common_dates]\n",
    "carhart_wml_betas = carhart_wml_betas.loc[common_dates]\n",
    "carhart_amd_betas = carhart_amd_betas.loc[common_dates]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fed9d2a2-9272-4336-ac20-b50dd493114f",
   "metadata": {},
   "source": [
    "# Initialize lists to store results\n",
    "betas_list = []\n",
    "\n",
    "# Loop over each available date in the returns DataFrame\n",
    "for date in common_dates:\n",
    "    # Cross-section of market caps, returns, and betas for that specific date\n",
    "    weights = np.sqrt(mkt_cap_df.loc[date])\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    # Returns\n",
    "    rets = pd.DataFrame([returns_df.loc[date]], index=['returns']).transpose()\n",
    "\n",
    "    # The Model Betas\n",
    "    mkt = pd.DataFrame([carhart_mkt_betas.loc[date]], index=['mkt']).transpose()\n",
    "    smb = pd.DataFrame([carhart_smb_betas.loc[date]], index=['smb']).transpose()\n",
    "    hml = pd.DataFrame([carhart_hml_betas.loc[date]], index=['hml']).transpose()\n",
    "    wml = pd.DataFrame([carhart_wml_betas.loc[date]], index=['wml']).transpose()\n",
    "    amd = pd.DataFrame([carhart_amd_betas.loc[date]], index=['amd']).transpose()\n",
    "    \n",
    "    # Merge returns with characteristics\n",
    "    reg_df_data = pd.concat([rets, mkt, smb, hml, wml, amd], axis=1).dropna()\n",
    "\n",
    "    # Define independent (X) and dependent (y) variables\n",
    "    X = sm.add_constant(reg_df_data[['mkt', 'smb', 'hml', 'wml', 'amd']])  \n",
    "    y = reg_df_data['returns']  \n",
    "\n",
    "    # Run the weighted least squares (WLS) regression\n",
    "    model = sm.WLS(y, X, missing='drop', weights=weights)\n",
    "    results = model.fit()\n",
    "\n",
    "    # Extract coefficients and p-values\n",
    "    params = results.params\n",
    "    #pvalues = results.pvalues\n",
    "    \n",
    "    # Set non-significant betas to zero (e.g., p > 0.05)\n",
    "    #significance_level = 0.1\n",
    "    #params[pvalues > significance_level] = 0\n",
    "    \n",
    "    # Store results\n",
    "    betas_list.append(pd.Series(params, name=date))\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "history_betas_df = pd.DataFrame(betas_list)\n",
    "\n",
    "# Set the index as the dates\n",
    "history_betas_df.index = common_dates"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4664befa-fe00-431b-bf8a-7a403c77bcc9",
   "metadata": {},
   "source": [
    "# Check the DataFrames\n",
    "\n",
    "history_betas_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6e8b930-fb41-4dea-b9d1-c2333787b899",
   "metadata": {},
   "source": [
    "# Create the Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_betas_df['mkt'].cumsum(), label='Market Beta Returns', alpha=0.7)\n",
    "plt.plot(history_betas_df['smb'].cumsum(), label='SMB Beta Returns', alpha=0.7)\n",
    "plt.plot(history_betas_df['hml'].cumsum(), label='HML Beta Returns', alpha=0.7)\n",
    "plt.plot(history_betas_df['wml'].cumsum(), label='WML Beta Returns', alpha=0.7)\n",
    "plt.plot(history_betas_df['amd'].cumsum(), label='AMD Beta Returns', alpha=0.7)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('Factor Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec36e077-da5c-4b29-8b45-bd817623ed1b",
   "metadata": {},
   "source": [
    "# Lets test the significance of these coefficients\n",
    "def newey_west_std(errors, lag=4):\n",
    "    \"\"\"\n",
    "    Computes Newey-West standard errors for a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    errors: Pandas Series or NumPy array of residuals (gamma estimates)\n",
    "    lag: Maximum number of lags to consider (default: 4)\n",
    "    \n",
    "    Returns:\n",
    "    Newey-West adjusted standard error\n",
    "    \"\"\"\n",
    "    T = len(errors)\n",
    "    gamma_var = errors.var()  # Start with variance of the series\n",
    "    \n",
    "    for l in range(1, lag + 1):\n",
    "        weight = 1 - (l / (lag + 1))\n",
    "        autocov = np.cov(errors[:-l], errors[l:])[0, 1]  # Autocovariance at lag l\n",
    "        gamma_var += 2 * weight * autocov  # Newey-West adjustment\n",
    "\n",
    "    return np.sqrt(gamma_var / T)  # Standard error\n",
    "\n",
    "def fama_macbeth_significance_test(gamma_series, lag=4):\n",
    "    \"\"\"\n",
    "    Performs statistical significance tests for Fama-MacBeth risk premia.\n",
    "\n",
    "    Parameters:\n",
    "    gamma_series: DataFrame where each column contains estimated gammas over time.\n",
    "    lag: Lags for Newey-West standard errors (default: 4).\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with mean gamma, standard error, t-statistics, and p-values.\n",
    "    \"\"\"\n",
    "    gamma_means = gamma_series.mean()\n",
    "\n",
    "    # Compute Newey-West adjusted standard errors\n",
    "    gamma_std = gamma_series.apply(newey_west_std, lag=lag)\n",
    "\n",
    "    # Compute t-statistics\n",
    "    t_stats = gamma_means / gamma_std\n",
    "\n",
    "    # Compute p-values\n",
    "    p_values = 2 * (1 - stats.t.cdf(abs(t_stats), df=len(gamma_series) - 1))\n",
    "\n",
    "    # Create results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'Mean Gamma': gamma_means,\n",
    "        'Std Error': gamma_std,\n",
    "        't-stat': t_stats,\n",
    "        'p-value': p_values\n",
    "    })\n",
    "\n",
    "    return results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d05083f4-fcf2-4f2e-a2b8-d9c732081aaf",
   "metadata": {},
   "source": [
    "# Now the Results\n",
    "\n",
    "results = fama_macbeth_significance_test(history_betas_df[['mkt', 'smb', 'hml', 'wml', 'amd']])\n",
    "\n",
    "results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741d4e6-0fe4-4184-8aba-2f26771b00fe",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
