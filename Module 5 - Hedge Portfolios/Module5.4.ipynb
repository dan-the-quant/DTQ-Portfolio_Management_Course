{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b56ebb-4959-4bb0-be39-410bfedca7cd",
   "metadata": {},
   "source": [
    "# Calculating Dollar-Neutral Portfolio #\n",
    "\n",
    "### Quarterly (63 days) Rebalancing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057afd9c-95d1-47ef-ae80-c712e8d0b6c8",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Data Management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistics\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Manipulate Files\n",
    "import os\n",
    "\n",
    "# Pretty Notation\n",
    "from IPython.display import display, Math"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f883cf84-b85b-4af5-bc7e-9762f27d6b84",
   "metadata": {},
   "source": [
    "# Get the important data for the Risk Free Rate\n",
    "rfr = pd.read_csv(r\"..\\additional_data\\rfr.csv\")\n",
    "rfr = rfr.set_index('Date')\n",
    "rfr.index = pd.to_datetime(rfr.index, dayfirst=True)\n",
    "rfr.dropna(inplace = True)\n",
    "\n",
    "# Get the important data for the S&P500\n",
    "sp500 = pd.read_csv(rf\"..\\additional_data\\sp500.csv\")\n",
    "sp500 = sp500.set_index('Date')\n",
    "sp500.index = pd.to_datetime(sp500.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e6d056-a5da-4aed-8714-0ed6457cc65b",
   "metadata": {},
   "source": [
    "# Dictionary to store the DataFrames\n",
    "folder_path = r\"..\\stocks\"\n",
    "\n",
    "dataframes = {} \n",
    "\n",
    "# List all files in the folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        # Full path to the file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.set_index(\"Date\")\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        df = df['Adjusted_close']\n",
    "\n",
    "        df = df.rename(\"adj_close\")\n",
    "        \n",
    "        # Fill nans\n",
    "        df = df.interpolate(method='time')\n",
    "\n",
    "        df = df.loc['2015-01-01':]\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        if len(df) >= 2000:\n",
    "            # File name without extension\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Guardar en el diccionario\n",
    "            dataframes[file_name] = df\n",
    "            print(f\"File loaded: {file_name} ({len(df)} rows)\")\n",
    "        else:\n",
    "            print(f\"File skipped (less than 2000 rows after cleaning): {file}\")\n",
    "\n",
    "print(f\"\\nTotal files loaded: {len(dataframes)}\")\n",
    "print(\"Files loaded:\", list(dataframes.keys()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d232a8-9f37-4a7a-9856-6ecf383cafc5",
   "metadata": {},
   "source": [
    "# Create the Returns DataFrame\n",
    "returns_dict = {}\n",
    "\n",
    "# Create the Loop to Obtain the Betas\n",
    "for ticker in dataframes.keys():\n",
    "    df = dataframes[ticker].pct_change(1).dropna()\n",
    "    returns_dict[ticker] = df\n",
    "\n",
    "# Create the DataFrame\n",
    "df_returns = pd.DataFrame.from_dict(returns_dict)\n",
    "df_returns = df_returns.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "df_returns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a301efa-ecc6-4ceb-ad3b-3caf08e019d2",
   "metadata": {},
   "source": [
    "# Calculate the Correlations Matrix\n",
    "corr_matrix = df_returns.corr().values  \n",
    "\n",
    "# Obtain Eigenvalues\n",
    "eigenvalues, _ = np.linalg.eigh(corr_matrix)\n",
    "\n",
    "# Identify how much Eigenvalues are small (high colineality)\n",
    "threshold = 1e-4  # Adjust\n",
    "num_redundant = sum(eigenvalues < threshold)\n",
    "\n",
    "print(f\"Number of highly colineal variables: {num_redundant}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36197bb7-4001-417e-bea5-43626380b717",
   "metadata": {},
   "source": [
    "# Let us Calculate the Weights\n",
    "def rolling_weights(\n",
    "    returns,\n",
    "    desired_returns,\n",
    "    window=252, \n",
    "    rebalance_freq=63\n",
    "):\n",
    "\n",
    "    # Lists to Store Things\n",
    "    weights_list = []\n",
    "    dates = []\n",
    "\n",
    "    for i in range(window, len(returns), rebalance_freq):\n",
    "        past_returns = returns.iloc[i-window:i]  # Rolling Window\n",
    "        \n",
    "        # Mean and Covariance\n",
    "        mu = past_returns.mean()\n",
    "        Sigma = past_returns.cov()\n",
    "\n",
    "        # Inverse\n",
    "        lambda_ = 1e-6  # Tikhonov Regularization\n",
    "        Sigma_inv = np.linalg.inv(Sigma + lambda_ * np.eye(Sigma.shape[0]))\n",
    "        \n",
    "        # Sigma_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "        # Ones\n",
    "        iota = np.ones(len(mu))\n",
    "\n",
    "        # Markowitz Components\n",
    "        A = mu @ Sigma_inv @ mu\n",
    "        B = mu @ Sigma_inv @ iota\n",
    "        C = iota @ Sigma_inv @ iota\n",
    "        D = (A * C) - (B ** 2)\n",
    "\n",
    "        w = ((desired_returns * C) / D) * (Sigma_inv @ mu) - \\\n",
    "            ((desired_returns * B) / D) * (Sigma_inv @ iota)\n",
    "\n",
    "        # Save weights and dates\n",
    "        weights_list.append(w)\n",
    "        dates.append(returns.index[i])\n",
    "\n",
    "    # Create the DataFrame\n",
    "    weights_df = pd.DataFrame(weights_list, index=dates, columns=returns.columns)\n",
    "\n",
    "    # Expand the DataFrame\n",
    "    weights_df = weights_df.reindex(returns.index, method='ffill')\n",
    "\n",
    "    return weights_df.dropna()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0250a70c-b5bd-4b8d-a418-caac5c156d5b",
   "metadata": {},
   "source": [
    "# Obtain the Weights\n",
    "\n",
    "benchmark_mean_returns = sp500.pct_change().mean()\n",
    "benchmark_mean_returns = benchmark_mean_returns.iloc[0]\n",
    "\n",
    "dnp_weights = rolling_weights(df_returns, benchmark_mean_returns)\n",
    "\n",
    "dnp_weights"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f8fa393-c214-40c1-8627-6aae03034936",
   "metadata": {},
   "source": [
    "# Calculate the DNP\n",
    "\n",
    "dnp_returns = ((df_returns * dnp_weights).dropna()).sum(axis = 1)\n",
    "dnp_returns.name = 'ZBP'\n",
    "\n",
    "dnp_returns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41c23e9d-4b95-494d-b504-74de65bd7d86",
   "metadata": {},
   "source": [
    "# Create Plot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dnp_returns.mul(100).cumsum(), label='DNP Returns', alpha=0.7)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('DNP Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c249c9fa-27c6-4a70-993f-d3450210c56c",
   "metadata": {},
   "source": [
    "# Calculate the beta\n",
    "risk_free_daily = (((1 + (rfr['risk_free_rate'].div(100)))**(1/360)) - 1)\n",
    "\n",
    "df_regression = pd.DataFrame()\n",
    "df_regression['y'] = dnp_returns - risk_free_daily\n",
    "df_regression['x'] = sp500['sp_500'].pct_change(1) - risk_free_daily\n",
    "df_regression.dropna(inplace = True)\n",
    "df_regression = df_regression.mul(100)\n",
    "\n",
    "df_regression"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ca1085b-f297-4b96-87d5-cd0293a2606b",
   "metadata": {},
   "source": [
    "# Create Plot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_regression['y'].cumsum(), label='Zero-Beta Portfolio Returns', color='red', alpha=0.7)\n",
    "plt.plot(df_regression['x'].cumsum(), label='Benchmark Returns', color='blue', alpha=0.7)\n",
    "\n",
    "# Config\n",
    "plt.title('Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6891efca-b766-4a95-9451-8f6356033ed4",
   "metadata": {},
   "source": [
    "# Create Figure\n",
    "fig, ax1 = plt.subplots(dpi = 300)\n",
    "\n",
    "# Market Returns Plot\n",
    "df_regression['x'].cumsum().plot(color = 'blue', ax = ax1, alpha=0.7)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel(\n",
    "    'Market Returns', \n",
    "    color='blue'\n",
    "    )\n",
    "\n",
    "# ZBP Returns Plot\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "df_regression['y'].cumsum().plot(color = 'red', ax = ax2, alpha=0.7)\n",
    "ax2.set_ylabel(\n",
    "    'Neutral Portfolio Returns', \n",
    "    color='red'\n",
    "    )\n",
    "\n",
    "plt.title('Beta vs Beta Time Series')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2667bc8-45be-461e-8a39-f7e329f3789f",
   "metadata": {},
   "source": [
    "# Correlation between market and our hedge portfolio\n",
    "\n",
    "df_regression.corr()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8cd8c57-5a69-4644-a028-88ab630f6ddd",
   "metadata": {},
   "source": [
    "# Create the Weights function\n",
    "def wexp(N, half_life):\n",
    "    c = np.log(0.5)/half_life\n",
    "    n = np.array(range(N))\n",
    "    w = np.exp(c*n)\n",
    "    return np.flip(w/np.sum(w))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c555115e-024a-4d9f-a7af-63ee07a59c59",
   "metadata": {},
   "source": [
    "#Model specification\n",
    "window = len(df_regression)\n",
    "weights = window * wexp(window, window/2)\n",
    "\n",
    "model = sm.WLS(\n",
    "    df_regression['y'], \n",
    "    sm.add_constant(df_regression['x']),\n",
    "    missing='drop',\n",
    "    weights=weights\n",
    "    )   \n",
    "     \n",
    "#the results of the model\n",
    "results = model.fit() \n",
    "    \n",
    "#here we check the summary\n",
    "print(results.summary()) "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d66fad5d-56b9-44ce-ac8c-2762d6100e9d",
   "metadata": {},
   "source": [
    "# Set rolling window size\n",
    "window = 252\n",
    "weights = window * wexp(window, window/2)\n",
    "\n",
    "y = df_regression['y']\n",
    "x = sm.add_constant(df_regression['x'])\n",
    "\n",
    "# Lists to store rolling coefficients\n",
    "params = []\n",
    "index = []\n",
    "lower_bounds = []\n",
    "upper_bounds = []\n",
    "\n",
    "# Rolling regression\n",
    "for i in range(window, len(df_regression)):\n",
    "    Y_window = y.iloc[i - window:i]\n",
    "    X_window = x.iloc[i - window:i]\n",
    "\n",
    "    # Fit WLS model\n",
    "    model = sm.WLS(Y_window, X_window, missing='drop', weights=weights).fit()\n",
    "\n",
    "    # Store coefficients (const, X1, X2)\n",
    "    params.append(model.params.values)\n",
    "    index.append(df_regression.index[i])  # Use the last date of the window\n",
    "\n",
    "    # Store lower and upper bounds of 95% confidence intervals\n",
    "    ci = model.conf_int(alpha=0.05)  # 95% CI\n",
    "    lower_bounds.append(ci.iloc[:, 0].values)  # First column: lower bound\n",
    "    upper_bounds.append(ci.iloc[:, 1].values)  # Second column: upper bound\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7eb06d5f-2327-47b1-995e-6f0d4b172489",
   "metadata": {},
   "source": [
    "# Convert list of coefficients to DataFrame\n",
    "parameters_df = pd.DataFrame(params, columns=x.columns, index=index)\n",
    "lower_df = pd.DataFrame(lower_bounds, columns=[f'{col}_lower' for col in x.columns], index=index)\n",
    "upper_df = pd.DataFrame(upper_bounds, columns=[f'{col}_upper' for col in x.columns], index=index)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d05c157f-fc6c-497c-b761-13b5bcba9287",
   "metadata": {},
   "source": [
    "# Create Plot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(parameters_df['x'], label='Market Beta', color='black', alpha=0.7)\n",
    "plt.fill_between(upper_df.index, lower_df['x_lower'], upper_df['x_upper'], color='yellow', alpha=0.2, label='95% CI')\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('Market Beta Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Betas')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92002c-5102-4229-bce3-2f261093e22f",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
