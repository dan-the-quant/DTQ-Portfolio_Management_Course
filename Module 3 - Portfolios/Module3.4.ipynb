{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9440b4-f688-4091-9872-4fdce8760b91",
   "metadata": {},
   "source": [
    "# Black-Litterman Portfolio's Theory #\n",
    "\n",
    "### Practical Example ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "586fa509-d79b-42a9-9e53-76ff62d6b9e2",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Data Management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optiminization\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Pretty Notation\n",
    "from IPython.display import display, Math"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "67f6d969-944d-448a-9ce5-10855bb405f2",
   "metadata": {},
   "source": [
    "def import_financial_data(\n",
    "    ticker: str\n",
    "):\n",
    "\n",
    "    # Check the ticker for Upper Cases\n",
    "    ticker = ticker if ticker.isupper() else ticker.upper()\n",
    "\n",
    "    # Import data\n",
    "    df = pd.read_csv(rf\"..\\stocks\\{ticker}.csv\")\n",
    "\n",
    "    # Set the Index\n",
    "    df = df.set_index('Date')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    df_useful_data = df[['Open Price', 'High Price', 'Low Price', 'Close Price', 'Adjusted_close', 'Company Market Cap']]\n",
    "\n",
    "    df_useful_data = df_useful_data.rename(columns={\n",
    "        \"Open Price\":\"open\",\n",
    "        \"High Price\":\"high\",\n",
    "        \"Low Price\":\"low\",\n",
    "        \"Close Price\":\"close\",\n",
    "        \"Adjusted_close\":\"adjusted_close\",\n",
    "        \"Company Market Cap\":\"mkt_cap\"\n",
    "    })\n",
    "\n",
    "    # Drop NaN's\n",
    "    df_useful_data.dropna(inplace = True)\n",
    "\n",
    "    return df_useful_data.loc[\"2023-01-01\":]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5f88e696-f8e9-4357-b83a-7c5550903335",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "\n",
    "# Apple Data\n",
    "df_1 = import_financial_data(\"AAPL\")\n",
    "\n",
    "# Amazon Data\n",
    "df_2 =  import_financial_data(\"AMZN\")\n",
    "\n",
    "# Meta Data\n",
    "df_3 =  import_financial_data(\"META\")\n",
    "\n",
    "# Microsoft Data\n",
    "df_4 =  import_financial_data(\"MSFT\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4061f88d-0310-4a5f-a57e-f92dd3a0c13c",
   "metadata": {},
   "source": [
    "# Create the joint dataframe\n",
    "df_data = pd.DataFrame()\n",
    "\n",
    "# Columns will be the Adjusted Close Price\n",
    "df_data['AAPL'] = df_1['adjusted_close']\n",
    "df_data['AMZN'] = df_2['adjusted_close']\n",
    "df_data['META'] = df_3['adjusted_close']\n",
    "df_data['MSFT'] = df_4['adjusted_close']\n",
    "\n",
    "# Drop Missing Data\n",
    "df_data = df_data.dropna()\n",
    "\n",
    "df_returns = df_data.pct_change(1).mul(100)\n",
    "df_returns = df_returns.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "df_returns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f6b6359d-3bb2-4aa0-8666-528ac44d7fb6",
   "metadata": {},
   "source": [
    "# Theoretically we could use the average as the expected returns (these are daily returns)\n",
    "expected_returns = df_returns.mean() \n",
    "\n",
    "expected_returns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "85c5a21c-db78-47a6-9969-68b0dc303487",
   "metadata": {},
   "source": [
    "# The volatility is calculated with the standard deviations (also daily volatilities)\n",
    "volat = df_returns.dropna().std() \n",
    "\n",
    "volat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0c0316ef-3fb3-480d-8754-206a034acff5",
   "metadata": {},
   "source": [
    "# Covariance Matrix\n",
    "cov_matrix = df_returns.dropna().cov()\n",
    "\n",
    "cov_matrix"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f6ffcb88-d580-4d1b-a3a1-320d51b10785",
   "metadata": {},
   "source": [
    "# Create the Market Capitalization \n",
    "df_mktcap = pd.DataFrame()\n",
    "\n",
    "df_mktcap['AAPL'] = df_1['mkt_cap']\n",
    "df_mktcap['AMZN'] = df_2['mkt_cap']\n",
    "df_mktcap['META'] = df_3['mkt_cap']\n",
    "df_mktcap['MSFT'] = df_4['mkt_cap']\n",
    "\n",
    "df_mktcap = df_mktcap.dropna()\n",
    "\n",
    "df_mktcap"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c06f6363-159c-4712-b844-881fd152bd95",
   "metadata": {},
   "source": [
    "# Create the Market Capitalization Weights\n",
    "\n",
    "total_market_cap = df_mktcap.sum(axis=1)  # Horizontal Sum because we got a Time Series\n",
    "\n",
    "df_mktcap_weights = df_mktcap.div(total_market_cap, axis = 0)\n",
    "\n",
    "df_mktcap_weights"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b4c3719f-cbd8-473a-80b0-35b16018f387",
   "metadata": {},
   "source": [
    "# Let us use the last observations since the mean of the portfolio is calculated with the whole story\n",
    "\n",
    "market_weights = df_mktcap_weights.iloc[-1]\n",
    "\n",
    "market_weights"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "bf2ec1db-39d7-49af-8eb4-db2e428dc927",
   "metadata": {},
   "source": [
    "# We can calculate or estimate the Risk Aversion Coefficient using market data, but let us assume it\n",
    "\n",
    "risk_aversion = 3.0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f2dbe8f2-e530-47af-a1ad-b22a3200743b",
   "metadata": {},
   "source": [
    "# Compute implied equilibrium returns\n",
    "\n",
    "pi = risk_aversion * cov_matrix @ market_weights\n",
    "\n",
    "pi"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b7eec9d5-dcf7-4b60-aa02-f90634b356c0",
   "metadata": {},
   "source": [
    "# Tau adjustment (controls uncertainty of implied returns)\n",
    "tau = 0.10\n",
    "\n",
    "pi_adjusted = tau * pi\n",
    "\n",
    "pi_adjusted"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "04daf604-f498-4d99-8979-499b7c08c561",
   "metadata": {},
   "source": [
    "# P matrix: 1 view per asset (identity matrix)\n",
    "P = np.identity(4)\n",
    "\n",
    "# Q vector: our expected returns relative to the market\n",
    "Q = np.array([0.01, 0.02, 0.05, 0.03])  # AAPL, AMZN, META, MSFT"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "71a871dd-7e62-4067-97ff-5daa6db45be2",
   "metadata": {},
   "source": [
    "# Diagonal Omega matrix: uncertainty of each view\n",
    "# Often proportional to variance of the assets related to the views\n",
    "Omega = np.diag(np.diag(P @ cov_matrix @ P.T)) * tau\n",
    "\n",
    "Omega"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2638bd37-00c1-4028-b8c0-0aefa3e39082",
   "metadata": {},
   "source": [
    "# Inverse Matrix\n",
    "\n",
    "inv_tau_sigma = np.linalg.inv(tau * cov_matrix)\n",
    "inv_omega = np.linalg.inv(Omega)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "4268128a-1bd7-41c4-90d8-5276680bf967",
   "metadata": {},
   "source": [
    "# Apply Black-Litterman formula\n",
    "\n",
    "posterior_mean = np.linalg.inv(inv_tau_sigma + P.T @ inv_omega @ P) @ (inv_tau_sigma @ pi + P.T @ inv_omega @ Q)\n",
    "\n",
    "posterior_mean"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e98629d6-66b8-4b62-9cf0-cf0ed13d0e30",
   "metadata": {},
   "source": [
    "# Calculate the Optimal Weights\n",
    "\n",
    "optimal_weights = np.linalg.inv(cov_matrix) @ (posterior_mean) / risk_aversion\n",
    "\n",
    "# Normalize weights to sum to 1\n",
    "\n",
    "optimal_weights /= np.sum(optimal_weights)\n",
    "\n",
    "optimal_weights"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "42cf7cac-d844-449b-8cbd-3e2ab929d42c",
   "metadata": {},
   "source": [
    "# Calculate the Portfolio Returns and Variance\n",
    "\n",
    "portfolio_returns = np.dot(optimal_weights, expected_returns)\n",
    "\n",
    "portfolio_variance = np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights))\n",
    "\n",
    "portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "\n",
    "print(f\"Expected Portfolio Return: {portfolio_returns:.4f}\")\n",
    "print(f\"Portfolio Variance: {portfolio_variance:.6f}\")\n",
    "print(f\"Portfolio Volatility (Std Dev): {portfolio_volatility:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f67a3f6a-9a97-476d-981f-9046d7b21a44",
   "metadata": {},
   "source": [
    "# Time Series Graphs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_data['AAPL'], label='APPL Price', color='blue', alpha=0.7)\n",
    "plt.plot(df_data['AMZN'], label='AMZN Price', color='green', alpha=0.7)\n",
    "plt.plot(df_data['META'], label='META Price', color='red', alpha=0.7)\n",
    "plt.plot(df_data['MSFT'], label='MSFT Price', color='orange', alpha=0.7)\n",
    "\n",
    "# Config\n",
    "plt.title('Prices Time Series')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('$P_t$')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "499e9063-0019-44a7-9a22-bb42e59fbc1a",
   "metadata": {},
   "source": [
    "# Calculate the Historical Returns of the Portfolio\n",
    "\n",
    "portfolio_returns = df_returns @ optimal_weights\n",
    "\n",
    "portfolio_returns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0406479a-9ae5-4169-a424-71d63a2d6c28",
   "metadata": {},
   "source": [
    "# Time Series Graphs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_returns['AAPL'].cumsum(), label='APPL Price', color='blue', alpha=0.7)\n",
    "plt.plot(df_returns['AMZN'].cumsum(), label='AMZN Price', color='green', alpha=0.7)\n",
    "plt.plot(df_returns['META'].cumsum(), label='META Price', color='red', alpha=0.7)\n",
    "plt.plot(df_returns['MSFT'].cumsum(), label='MSFT Price', color='orange', alpha=0.7)\n",
    "plt.plot(portfolio_returns.cumsum(), label='BL Portfolio', color='purple', alpha=0.7)\n",
    "\n",
    "# Config\n",
    "plt.title('Cumulative Returns Time Series')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a51d3e8c-a50f-4961-98c6-be2b6b5d3b74",
   "metadata": {},
   "source": [
    "def calculate_analytics(df_returns, risk_free_rate=0.0):\n",
    "    # Trading Days in one Year\n",
    "    ann_factor = 252  \n",
    "    \n",
    "    # Annualized Returns\n",
    "    annualized_return = df_returns.mean() * ann_factor\n",
    "    \n",
    "    # Annualized Volatility\n",
    "    annualized_std = df_returns.std() * np.sqrt(ann_factor)\n",
    "    \n",
    "    # Sharpe Ratio\n",
    "    sharpe_ratio = (annualized_return - risk_free_rate) / annualized_std\n",
    "    \n",
    "    # Max Drawdown\n",
    "    cumulative_returns = (1 + df_returns.div(100)).cumprod()\n",
    "    rolling_max = cumulative_returns.cummax()\n",
    "    drawdown = (cumulative_returns / rolling_max) - 1\n",
    "    max_drawdown = drawdown.min()\n",
    "\n",
    "    # VaR at 95%\n",
    "    var_95 = df_returns.quantile(0.05)\n",
    "\n",
    "    # Create DF\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Annualized Returns\": annualized_return,\n",
    "        \"Annualized Volatility\": annualized_std,\n",
    "        \"Sharpe Ratio\": sharpe_ratio,\n",
    "        \"Max Drawdown\": max_drawdown,\n",
    "        \"VaR 95%\": var_95\n",
    "    })\n",
    "    \n",
    "    return summary_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "62d821f4-d410-4104-8328-2b928f8829ac",
   "metadata": {},
   "source": [
    "# Create the Analytics\n",
    "\n",
    "df_returns['BL'] = portfolio_returns\n",
    "\n",
    "df_returns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "92977b7b-218f-4c26-9d8a-ae84a14be0b3",
   "metadata": {},
   "source": [
    "# Now the table\n",
    "analytics_table = calculate_analytics(df_returns)\n",
    "\n",
    "analytics_table"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea138ea-41d7-4a4c-8c11-ed06876d21d3",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
