{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6167a95a-9409-4bf2-a80b-3c5442068ca5",
   "metadata": {},
   "source": [
    "# Calculating Betas for the Market's Stocks #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3bd64c-d382-4d88-83e5-ed580e6c1c85",
   "metadata": {},
   "source": [
    "### Calculating the Betas for all the Stocks in the Universe ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c3c119-5b8f-4301-a714-ced12c33630a",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Data Management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistics\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Manipulate Files\n",
    "import os\n",
    "\n",
    "# Pretty Notation\n",
    "from IPython.display import display, Math"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8669f9-bcf9-49e5-92b2-52c6e3dad8ea",
   "metadata": {},
   "source": [
    "# Get the important data for the Risk Free Rate\n",
    "\n",
    "rfr = pd.read_csv(rf\"..\\additional_data\\rfr.csv\")\n",
    "rfr = rfr.set_index('Date')\n",
    "rfr.index = pd.to_datetime(rfr.index, dayfirst=True)\n",
    "rfr.dropna(inplace = True)\n",
    "\n",
    "# Get the important data for the S&P500\n",
    "\n",
    "sp500 = pd.read_csv(rf\"..\\additional_data\\sp500.csv\")\n",
    "sp500 = sp500.set_index('Date')\n",
    "sp500.index = pd.to_datetime(sp500.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad2da435-3a15-4864-bd80-49f3a60b8476",
   "metadata": {},
   "source": [
    "# Create the Weights function\n",
    "def wexp(N, half_life):\n",
    "    c = np.log(0.5)/half_life\n",
    "    n = np.array(range(N))\n",
    "    w = np.exp(c*n)\n",
    "    return np.flip(w/np.sum(w))\n",
    "\n",
    "# Create the CAPM \n",
    "def CAPM(\n",
    "    stock_prices: pd.Series, \n",
    "    benchmark_prices: pd.Series = sp500['sp_500'], \n",
    "    risk_free_rate: pd.Series = rfr['risk_free_rate'], \n",
    "    window: int = 252,\n",
    "    WLS: bool = True,\n",
    "):\n",
    "\n",
    "    # Align time series to the same date range\n",
    "    common_index = stock_prices.index.intersection(benchmark_prices.index).intersection(risk_free_rate.index)\n",
    "    stock_prices = stock_prices.loc[common_index]\n",
    "    benchmark_prices = benchmark_prices.loc[common_index]\n",
    "    risk_free_rate = risk_free_rate.loc[common_index]\n",
    "    \n",
    "    # Compute daily returns\n",
    "    stock_returns = stock_prices.pct_change(1)\n",
    "    benchmark_returns = benchmark_prices.pct_change(1)\n",
    "    risk_free_daily = (((1 + (risk_free_rate.div(100)))**(1/360)) - 1)  # Convert annual rate to daily\n",
    "    \n",
    "    # Excess returns\n",
    "    excess_stock = stock_returns - risk_free_daily\n",
    "    excess_benchmark = benchmark_returns - risk_free_daily\n",
    "\n",
    "    alphas, betas = [], []\n",
    "\n",
    "    # Create weights with exponential decay\n",
    "    weights = window * wexp(window, window/2)\n",
    "    \n",
    "    for t in range(window, len(stock_returns)):\n",
    "        X = excess_benchmark.iloc[t-window:t]\n",
    "        y = excess_stock.iloc[t-window:t]\n",
    "        \n",
    "        if X.isnull().any() or y.isnull().any():\n",
    "            continue\n",
    "\n",
    "        if WLS:\n",
    "            \n",
    "            # Fit WLS regression\n",
    "            model = sm.WLS(y, sm.add_constant(X), weights=weights, missing='drop').fit()\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Fit OLS regression\n",
    "            model = sm.OLS(y, sm.add_constant(X), missing='drop').fit()\n",
    "\n",
    "        # Avoid KeyError by checking if params exist\n",
    "        params = model.params\n",
    "        \n",
    "        alphas.append(params.iloc[0])\n",
    "        betas.append(params.iloc[1])\n",
    "            \n",
    "    parameters = pd.DataFrame({\n",
    "        'alpha': alphas,\n",
    "        'beta': betas,\n",
    "    }, index=stock_returns.index[window+1:])\n",
    "    \n",
    "    return parameters"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2f42fa5-2652-4c03-a938-6c049684064f",
   "metadata": {},
   "source": [
    "# Dictionary to store the DataFrames\n",
    "folder_path = r\"..\\stocks\"\n",
    "\n",
    "dataframes = {} \n",
    "\n",
    "# List all files in the folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        # Full path to the file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.set_index(\"Date\")\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        df = df['Adjusted_close']\n",
    "\n",
    "        df = df.rename(\"adj_close\")\n",
    "        \n",
    "        # Fill nans\n",
    "        df = df.interpolate(method='time')\n",
    "\n",
    "        df = df.loc['2015-01-01':]\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        if len(df) >= 2000:\n",
    "            # File name without extension\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Guardar en el diccionario\n",
    "            dataframes[file_name] = df\n",
    "            print(f\"File loaded: {file_name} ({len(df)} rows)\")\n",
    "        else:\n",
    "            print(f\"File skipped (less than 2000 rows after cleaning): {file}\")\n",
    "\n",
    "print(f\"\\nTotal files loaded: {len(dataframes)}\")\n",
    "print(\"Files loaded:\", list(dataframes.keys()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dac2b59-1cf0-4c76-8b5c-bd14e8cbcf7e",
   "metadata": {},
   "source": [
    "# Let us obtain the betas of each stock\n",
    "\n",
    "betas_dict = {}\n",
    "\n",
    "# Create the Loop to Obtain the Betas\n",
    "for ticker in dataframes.keys():\n",
    "    df = CAPM(dataframes[ticker])\n",
    "    betas_dict[ticker] = df['beta']\n",
    "\n",
    "    print(f'{ticker} is ready.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "996909b2-cdaf-4cdf-9e6a-c56c11ee58eb",
   "metadata": {},
   "source": [
    "# Create the DataFrame\n",
    "betas_df = pd.DataFrame.from_dict(betas_dict)\n",
    "betas_df = betas_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "betas_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c50ebfe-bd15-4668-b1b8-e28f69578e4a",
   "metadata": {},
   "source": [
    "# Save the betas\n",
    "\n",
    "betas_df.to_csv(r\"..\\additional_data\\betas.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e97e75-4a32-4f06-a689-07b1ec8c4a62",
   "metadata": {},
   "source": [
    "# Create the Returns DataFrame\n",
    "returns_dict = {}\n",
    "\n",
    "# Create the Loop to Obtain the Betas\n",
    "for ticker in dataframes.keys():\n",
    "    df = dataframes[ticker].pct_change(1).dropna()\n",
    "    returns_dict[ticker] = df\n",
    "\n",
    "# Create the DataFrame\n",
    "df_returns = pd.DataFrame.from_dict(returns_dict)\n",
    "df_returns = df_returns.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "df_returns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "041d9fed-9f53-4731-835a-954b422604ac",
   "metadata": {},
   "source": [
    "# Calculate the Whole Story Betas\n",
    "\n",
    "# Create useful series\n",
    "risk_free_daily = (((1 + (rfr['risk_free_rate'].div(100)))**(1/360)) - 1)\n",
    "market_returns = sp500['sp_500'].pct_change(1).dropna()\n",
    "\n",
    "# Common Indexes\n",
    "common_index = df_returns.index.intersection(risk_free_daily.index).intersection(market_returns.index)\n",
    "df_returns, risk_free_daily, market_returns = df_returns.loc[common_index], risk_free_daily.loc[common_index], market_returns.loc[common_index]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb32725-5fc5-49b9-af3c-0712b4652748",
   "metadata": {},
   "source": [
    "# Create Weights\n",
    "window = len(df_returns)\n",
    "weights = window * wexp(window, window/2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(weights, label='Weights', color='black', alpha=0.7)\n",
    "\n",
    "# Config\n",
    "plt.title('Weights (no flip) Graph')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Weights')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e74f5f0d-d33a-474b-ae35-7247ed78a4f6",
   "metadata": {},
   "source": [
    "# Create the Historical Betas and Alpha + Residuals DataFrames\n",
    "betas_dict = {}\n",
    "alpha_resids_df = pd.DataFrame(index=df_returns.index)\n",
    "\n",
    "# Loop to Obtain Betas and Alpha + Residuals\n",
    "for ticker in df_returns.columns:\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = df_returns[ticker] - risk_free_daily\n",
    "    df['x'] = market_returns - risk_free_daily\n",
    "\n",
    "    # Drop NaNs\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Add constant (alpha term)\n",
    "    X = sm.add_constant(df['x'])\n",
    "    y = df['y']\n",
    "\n",
    "    # Fit the WLS model\n",
    "    model = sm.WLS(y, X, weights=weights, missing='drop').fit()\n",
    "\n",
    "    # Extract Alpha and Beta\n",
    "    alpha = model.params['const']\n",
    "    beta = model.params['x']\n",
    "\n",
    "    # Store Beta\n",
    "    betas_dict[ticker] = beta\n",
    "\n",
    "    # Compute (Alpha + Residuals)\n",
    "    alpha_residuals = model.resid + alpha  # Add alpha to residuals\n",
    "\n",
    "    # Store Alpha + Residuals\n",
    "    alpha_resids_df = pd.concat([alpha_resids_df, alpha_residuals.rename(ticker)], axis=1)\n",
    "\n",
    "# Create Beta Series\n",
    "betas_series = pd.Series(betas_dict)\n",
    "\n",
    "betas_series"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26e76ce8-f383-430d-886b-f507e269fa07",
   "metadata": {},
   "source": [
    "alpha_resids_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc21f71-4e3d-4f91-9269-16283787cc99",
   "metadata": {},
   "source": [
    "# Save the betas\n",
    "alpha_resids_df.to_csv(r\"..\\additional_data\\capm_residuals.csv\")\n",
    "betas_series.to_csv(r\"..\\additional_data\\historical_betas.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e657ff5-ff0f-4c58-b24b-814fc0b116c7",
   "metadata": {},
   "source": [
    "# Plot\n",
    "ticker = 'NVDA'\n",
    "\n",
    "# Mean\n",
    "mean = betas_df[ticker].mean()\n",
    "\n",
    "# Create the Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(betas_df[ticker], label=f'{ticker} Beta', color='blue', alpha=0.7)\n",
    "plt.axhline(y=betas_series.loc[ticker], color='red', linestyle='dashed', label=f'{ticker} Historical Beta')\n",
    "plt.axhline(y=mean, color='black', linestyle='dashed', label=f'{ticker} Mean Beta')\n",
    "\n",
    "# Config\n",
    "plt.title('Beta Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Betas')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b436f93-37d3-4ceb-b2dc-3507273565b3",
   "metadata": {},
   "source": [
    "# Plot\n",
    "ticker = 'AAPL'\n",
    "\n",
    "# Create the Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_returns[ticker].cumsum(), label=f'{ticker} Returns', alpha=0.7)\n",
    "plt.plot(alpha_resids_df[ticker].cumsum(), label=f'{ticker} Residual Returns', alpha=0.7)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e330dbc1-0c1c-4650-963b-7c7724a3c1e8",
   "metadata": {},
   "source": [
    "# Compare Volatility and Betas for each stock\n",
    "\n",
    "anualized_vol = df_returns[ticker].std() * np.sqrt(252)\n",
    "comparison = betas_series.loc[ticker]/anualized_vol\n",
    "\n",
    "print(f'{ticker} Historical Beta is: {betas_series.loc[ticker]}')\n",
    "print(f'{ticker} Historical Annualized Standard Deviation is: {anualized_vol}')\n",
    "print(f'{ticker} Ratio Between Both is: {comparison}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97315d13-69d6-4efd-8d5a-cf479197cd15",
   "metadata": {},
   "source": [
    "# Calculate Mean and Standard Deviation\n",
    "mu = betas_series.mean()\n",
    "sigma = betas_series.std()\n",
    "\n",
    "# Create Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(betas_series, bins=30, density=True, color='lightskyblue', alpha=0.5, edgecolor='black', label='Betas Distribution')\n",
    "\n",
    "# Generate the Values of the Normal Distribution\n",
    "x = np.linspace(betas_series.min(), betas_series.max(), 100)\n",
    "y = norm.pdf(x, mu, sigma)\n",
    "\n",
    "# Graph the Real Normal Distribution\n",
    "plt.plot(x, y, color='black', linestyle='solid', linewidth=2, label='Normal Distribution')\n",
    "\n",
    "# Reference Lines\n",
    "plt.axvline(x=mu, color='black', linestyle='dashed', label='Mean Returns')\n",
    "plt.axvline(x=betas_series.median(), color='red', linestyle='dashed', label='Median Returns')\n",
    "plt.axvline(x=mu + sigma, color='grey', linestyle='dashed')\n",
    "plt.axvline(x=mu - sigma, color='grey', linestyle='dashed')\n",
    "\n",
    "# Config\n",
    "plt.title('Betas Histogram with Normal Distribution')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Legends and Grid\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c772f-007c-4559-9e30-10b25c3bcfb9",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
