{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64d7451-b410-4675-896b-979996f980fd",
   "metadata": {},
   "source": [
    "# Fama-MacBeth Regression #\n",
    "\n",
    "### Size, Value and Beta ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad744288-e299-4dd0-8d67-c7fbdd91ecb3",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Data Management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Manipulate Files\n",
    "import os\n",
    "\n",
    "# Pretty Notation\n",
    "from IPython.display import display, Math"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92a72a1-3b54-4e29-8ccf-a02396909126",
   "metadata": {},
   "source": [
    "# Dictionary to store the DataFrames\n",
    "folder_path = r\"..\\stocks\"\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "# List all files in the folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        # Full path to the file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.set_index(\"Date\")\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        df = df[['Adjusted_close', 'Company Market Cap']]\n",
    "\n",
    "        df = df.rename(columns={\n",
    "            'Adjusted_close':'adj_close',\n",
    "            'Company Market Cap':'market_cap',\n",
    "        })\n",
    "\n",
    "        # Fill nans\n",
    "        df['adj_close'] = df['adj_close'].interpolate(method='time')\n",
    "        df['market_cap'] = df['market_cap'].interpolate(method='time')\n",
    "\n",
    "        df = df.loc['2015-01-01':]\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        if len(df) >= 2000:\n",
    "            # File name without extension\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Guardar en el diccionario\n",
    "            dataframes[file_name] = df\n",
    "            print(f\"File loaded: {file_name} ({len(df)} rows)\")\n",
    "        else:\n",
    "            print(f\"File skipped (less than 2000 rows after cleaning): {file}\")\n",
    "\n",
    "print(f\"\\nTotal files loaded: {len(dataframes)}\")\n",
    "print(\"Files loaded:\", list(dataframes.keys()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23cb89f7-5ce7-43bf-91b9-52979e00a5a8",
   "metadata": {},
   "source": [
    "# Get the important data for the Risk Free Rate\n",
    "\n",
    "rfr = pd.read_csv(r\"..\\additional_data\\rfr.csv\")\n",
    "rfr = rfr.set_index('Date')\n",
    "rfr.index = pd.to_datetime(rfr.index, dayfirst=True)\n",
    "\n",
    "# Get the important data for the S&P500\n",
    "\n",
    "sp500 = pd.read_csv(r\"..\\additional_data\\sp500.csv\")\n",
    "sp500 = sp500.set_index('Date')\n",
    "sp500.index = pd.to_datetime(sp500.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c10ff5-84ba-4a01-9b05-55fc4661f061",
   "metadata": {},
   "source": [
    "# Get the important data for the Betas\n",
    "\n",
    "ff_betas = pd.read_csv(r\"..\\additional_data\\famafrench_betas.csv\")\n",
    "ff_betas = ff_betas.rename(columns={'Unnamed: 0': 'ticker'})\n",
    "ff_betas.set_index('ticker', inplace = True)\n",
    "\n",
    "ff_betas"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7318c4-4385-44a7-a00d-a398f84ea052",
   "metadata": {},
   "source": [
    "# Create a DataFrame\n",
    "mkt_cap_dict = {}\n",
    "\n",
    "# Recorrer cada ticker y DataFrame\n",
    "for ticker, df in dataframes.items():\n",
    "    \n",
    "    mkt_cap_dict[ticker] = df['market_cap']\n",
    "\n",
    "mkt_cap_df = pd.DataFrame.from_dict(mkt_cap_dict)\n",
    "\n",
    "mkt_cap_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4d9e6e3-3dc3-4597-8ad7-0dbc06ad0a27",
   "metadata": {},
   "source": [
    "# Let us obtain the betas of each stock\n",
    "\n",
    "returns_dic = {}\n",
    "\n",
    "for ticker, df in dataframes.items():\n",
    "    \n",
    "    returns_dic[ticker] = df['adj_close'].pct_change(1)\n",
    "\n",
    "returns_df = pd.DataFrame.from_dict(returns_dic)\n",
    "returns_df = returns_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "returns_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90adc05-9fdc-4bca-9ae2-ceb6406353d1",
   "metadata": {},
   "source": [
    "# Intersec Dates\n",
    "common_dates = returns_df.index.intersection(mkt_cap_df.index)\n",
    "\n",
    "# Filter for common dates\n",
    "mkt_cap_df = mkt_cap_df.loc[common_dates]\n",
    "returns_df = returns_df.loc[common_dates]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e30b5d3-355b-4af6-be4e-9940e5850c3e",
   "metadata": {},
   "source": [
    "# Initialize lists to store results\n",
    "betas_list = []\n",
    "\n",
    "# Loop over each available date in the returns DataFrame\n",
    "for date in common_dates:\n",
    "    # Cross-section of market caps, returns, and betas for that specific date\n",
    "    weights = np.sqrt(mkt_cap_df.loc[date])\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    rets = pd.DataFrame([returns_df.loc[date]], index=['returns']).transpose()\n",
    "    \n",
    "    # Merge returns with characteristics\n",
    "    reg_df_data = pd.concat([rets, ff_betas], axis=1).dropna()\n",
    "\n",
    "    # Define independent (X) and dependent (y) variables\n",
    "    X = sm.add_constant(reg_df_data[['capm_beta', 'smb_beta', 'hml_beta']])  \n",
    "    y = reg_df_data['returns']  \n",
    "\n",
    "    # Run the weighted least squares (WLS) regression\n",
    "    model = sm.WLS(y, X, missing='drop', weights=weights)\n",
    "    results = model.fit()\n",
    "\n",
    "    # Extract coefficients, t-stats, and p-values\n",
    "    params = results.params\n",
    "\n",
    "    # Store results in separate lists\n",
    "    betas_list.append(pd.Series(params, name=date)) \n",
    "\n",
    "# Convert lists to DataFrames\n",
    "history_betas_df = pd.DataFrame(betas_list)\n",
    "\n",
    "# Set the index as the dates\n",
    "history_betas_df.index = common_dates\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eadb27b4-1efe-4082-89cd-270a28b34a1c",
   "metadata": {},
   "source": [
    "# Check the DataFrames\n",
    "\n",
    "history_betas_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21cb0f2a-920f-4a59-b1c6-44d477a7f0b6",
   "metadata": {},
   "source": [
    "# Create the Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_betas_df['capm_beta'].cumsum(), label='Market Beta Returns', alpha=0.7)\n",
    "plt.plot(history_betas_df['smb_beta'].cumsum(), label='SMB Beta Returns', alpha=0.7)\n",
    "plt.plot(history_betas_df['hml_beta'].cumsum(), label='HML Beta Returns', alpha=0.7)\n",
    "\n",
    "# Config\n",
    "plt.title('Factor Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d63870a-ac22-4f77-97fe-a90a05456eaa",
   "metadata": {},
   "source": [
    "# Get the data for the SMB Premium\n",
    "SMB = pd.read_csv(r\"..\\additional_data\\SMB.csv\")\n",
    "SMB = SMB.set_index('Date')\n",
    "SMB.index = pd.to_datetime(SMB.index)\n",
    "\n",
    "# Get the data for the HML Premium\n",
    "HML = pd.read_csv(r\"..\\additional_data\\HML.csv\")\n",
    "HML = HML.set_index('Date')\n",
    "HML.index = pd.to_datetime(HML.index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75911991-acba-41c5-90d0-cc4bd221c65a",
   "metadata": {},
   "source": [
    "# Create the Plot\n",
    "# Create the data\n",
    "daily_rfr = (((1 + (rfr['risk_free_rate'].div(100)))**(1/360)) - 1)\n",
    "benchmark_returns = sp500['sp_500'].pct_change(1)\n",
    "\n",
    "# Create the Excess Returns\n",
    "market_excess_returns = benchmark_returns - daily_rfr\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_betas_df['capm_beta'].cumsum(), label='Regression Market Beta Returns', alpha=0.7)\n",
    "plt.plot(market_excess_returns.cumsum(), label='Calculated Market Beta Returns', alpha=0.7)\n",
    "\n",
    "# Config\n",
    "plt.title('Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79e84d17-70ff-4ce5-997c-477c74d700f7",
   "metadata": {},
   "source": [
    "# Create the Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_betas_df['smb_beta'].cumsum(), label='Regression SMB Beta Returns', alpha=0.7)\n",
    "plt.plot(SMB.cumsum(), label='Calculated SMB Beta Returns', alpha=0.7)\n",
    "\n",
    "# Config\n",
    "plt.title('Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e8ab6d6-fe11-44f5-9d32-297356bdead4",
   "metadata": {},
   "source": [
    "# Create the Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_betas_df['hml_beta'].cumsum(), label='Regression HML Beta Returns', alpha=0.7)\n",
    "plt.plot(HML.cumsum(), label='Calculated HML Beta Returns', alpha=0.7)\n",
    "\n",
    "# Config\n",
    "plt.title('Returns Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6803e81f-6138-41d5-bd61-26114fee099a",
   "metadata": {},
   "source": [
    "# Lets test the significance of these coefficients\n",
    "def newey_west_std(errors, lag=4):\n",
    "    \"\"\"\n",
    "    Computes Newey-West standard errors for a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    errors: Pandas Series or NumPy array of residuals (gamma estimates)\n",
    "    lag: Maximum number of lags to consider (default: 4)\n",
    "    \n",
    "    Returns:\n",
    "    Newey-West adjusted standard error\n",
    "    \"\"\"\n",
    "    T = len(errors)\n",
    "    gamma_var = errors.var()  # Start with variance of the series\n",
    "    \n",
    "    for l in range(1, lag + 1):\n",
    "        weight = 1 - (l / (lag + 1))\n",
    "        autocov = np.cov(errors[:-l], errors[l:])[0, 1]  # Autocovariance at lag l\n",
    "        gamma_var += 2 * weight * autocov  # Newey-West adjustment\n",
    "\n",
    "    return np.sqrt(gamma_var / T)  # Standard error\n",
    "\n",
    "def fama_macbeth_significance_test(gamma_series, lag=4):\n",
    "    \"\"\"\n",
    "    Performs statistical significance tests for Fama-MacBeth risk premia.\n",
    "\n",
    "    Parameters:\n",
    "    gamma_series: DataFrame where each column contains estimated gammas over time.\n",
    "    lag: Lags for Newey-West standard errors (default: 4).\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with mean gamma, standard error, t-statistics, and p-values.\n",
    "    \"\"\"\n",
    "    gamma_means = gamma_series.mean()\n",
    "\n",
    "    # Compute Newey-West adjusted standard errors\n",
    "    gamma_std = gamma_series.apply(newey_west_std, lag=lag)\n",
    "\n",
    "    # Compute t-statistics\n",
    "    t_stats = gamma_means / gamma_std\n",
    "\n",
    "    # Compute p-values\n",
    "    p_values = 2 * (1 - stats.t.cdf(abs(t_stats), df=len(gamma_series) - 1))\n",
    "\n",
    "    # Create results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'Mean Gamma': gamma_means,\n",
    "        'Std Error': gamma_std,\n",
    "        't-stat': t_stats,\n",
    "        'p-value': p_values\n",
    "    })\n",
    "\n",
    "    return results\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "321b3fa9-a9f9-493f-96e4-a3717d54cf73",
   "metadata": {},
   "source": [
    "# Now the Results\n",
    "\n",
    "results = fama_macbeth_significance_test(history_betas_df[['capm_beta',\t'smb_beta',\t'hml_beta']])\n",
    "\n",
    "results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dbad13e-f7bc-4ce2-8823-f1a255c9c7a2",
   "metadata": {},
   "source": [
    "# Chi^2 test sobre alphas\n",
    "# está en el paper de FF"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
